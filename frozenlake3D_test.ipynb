{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import grid_world_3d\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_SPACE = (0, 1, 2, 3, 4, 5)\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "def generate_random_policy(grid):\n",
    "    P = {}\n",
    "    for s in grid.non_terminal_states():\n",
    "        P[s] = np.random.choice(ACTION_SPACE)\n",
    "    return P\n",
    "\n",
    "def random_policy_iteration(grid, threshold = 0):\n",
    "    np.random.seed(123)\n",
    "    policy = {}\n",
    "    while True:\n",
    "        grid.set_state([2, 0, 0])\n",
    "        policy = generate_random_policy(grid)\n",
    "        total_reward = 0\n",
    "        nsteps = 0\n",
    "        while not (grid.game_over() or nsteps > 40):\n",
    "            total_reward += grid.move(policy[grid.current_state()])\n",
    "            nsteps += 1\n",
    "        if total_reward > threshold:\n",
    "            break\n",
    "    return policy, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_action_value(grid, V, s, gamma = 0.9):\n",
    "    action = None\n",
    "    val = float('-inf')\n",
    "    grid.set_state(s)\n",
    "    \n",
    "    for a in ACTION_SPACE:\n",
    "        transitions = grid.get_transition_probs(a)\n",
    "        v = 0\n",
    "        r = 0\n",
    "        for (P, rew, state) in transitions:\n",
    "            r += P * rew\n",
    "            v += P * V[state]\n",
    "        v = r + gamma * v\n",
    "        if v > val:\n",
    "            val = v\n",
    "            action = a\n",
    "    \n",
    "    return action, val\n",
    "\n",
    "def value_iteration(grid, threshold = 1e-3, gamma = 0.9):\n",
    "    V = {}\n",
    "    for s in grid.all_states():\n",
    "        V[s] = 0\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in grid.non_terminal_states():\n",
    "            val = V[s]\n",
    "            _, V[s] = best_action_value(grid, V, s, gamma)\n",
    "            delta = max(delta, abs(val - V[s]))\n",
    "            \n",
    "        if delta < threshold:\n",
    "            break\n",
    "    \n",
    "    policy = generate_random_policy(grid)\n",
    "    for s in policy.keys():\n",
    "        grid.set_state(s)\n",
    "        policy[s], _ = best_action_value(grid, V, s, gamma)\n",
    "    \n",
    "    return V, policy\n",
    "\n",
    "def run_episode(grid, policy):\n",
    "    total_reward = 0\n",
    "    grid.set_state((2, 0, 0))\n",
    "    while not grid.game_over():\n",
    "        total_reward += grid.move(policy[grid.current_state()])\n",
    "        print(grid.current_state())\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Policy: 1 reward\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 2)\n",
      "(0, 1, 2)\n",
      "(0, 2, 2)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "myenv = grid_world_3d.standard_grid3D(obey_prob=1.0,step_cost=None)\n",
    "good_policy, reward = random_policy_iteration(myenv)\n",
    "print(\"Best Policy: {0} reward\".format(reward))\n",
    "print(run_episode(myenv, good_policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 0)\n",
      "(1, 1, 0)\n",
      "(0, 1, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "best_value, best_policy = value_iteration(myenv)\n",
    "print(run_episode(myenv, best_policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Policy: 1.1102230246251565e-16 reward\n",
      "(2, 0, 0)\n",
      "(2, 0, 0)\n",
      "(2, 0, 0)\n",
      "(2, 0, 0)\n",
      "(2, 0, 0)\n",
      "(1, 0, 0)\n",
      "(1, 0, 0)\n",
      "(0, 0, 0)\n",
      "-1.7\n"
     ]
    }
   ],
   "source": [
    "mydrunkenenv = grid_world_3d.standard_grid3D(obey_prob=0.8,step_cost=-0.1)\n",
    "good_policy, reward = random_policy_iteration(mydrunkenenv)\n",
    "print(\"Best Policy: {0} reward\".format(reward))\n",
    "print(run_episode(mydrunkenenv, good_policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0, 1)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(0, 0, 2)\n",
      "(0, 1, 2)\n",
      "(0, 2, 2)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "best_value, best_policy = value_iteration(mydrunkenenv)\n",
    "print(run_episode(mydrunkenenv, best_policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Policy: -5 reward\n",
      "(2, 1, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 1, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 1, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 2, 0)\n",
      "(2, 1, 0)\n",
      "(1, 1, 0)\n",
      "(0, 1, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 1)\n",
      "(0, 2, 1)\n",
      "(0, 2, 1)\n",
      "(0, 1, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 0, 2)\n",
      "(0, 0, 2)\n",
      "(0, 0, 2)\n",
      "(0, 0, 2)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "(0, 0, 0)\n",
      "-347\n"
     ]
    }
   ],
   "source": [
    "mysuicideenv = grid_world_3d.standard_grid3D(obey_prob=0.8,step_cost=-2)\n",
    "good_policy, reward = random_policy_iteration(mysuicideenv, threshold = -8)\n",
    "print(\"Best Policy: {0} reward\".format(reward))\n",
    "print(run_episode(mysuicideenv, good_policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 0)\n",
      "(0, 0, 0)\n",
      "-3\n"
     ]
    }
   ],
   "source": [
    "best_value, best_policy = value_iteration(mysuicideenv)\n",
    "print(run_episode(mysuicideenv, best_policy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
